{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Getting Started with OpanAI**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to Generate an OpenAI API Key\n",
    "1. Go to OpenAI API:\n",
    "    - Open your browser and visit https://openai.com/api.\n",
    "\n",
    "2. Login to OpenAI:\n",
    "    - Click on \"Login\" in the top-right corner.\n",
    "    - Select \"API Platform\" and log in with your OpenAI credentials.\n",
    "\n",
    "3. Go to the Dashboard:\n",
    "\n",
    "    - Once logged in, you will be redirected to the API Dashboard.\n",
    "\n",
    "4. Navigate to API Keys:\n",
    "\n",
    "    - On the left-hand menu, click \"API Keys\".\n",
    "\n",
    "5. Create a New Secret Key:\n",
    "    - Click on the \"Create new secret key\" button.\n",
    "    - A new API key will be generated.\n",
    "\n",
    "6. Copy and Save Your API Key:\n",
    "\n",
    "Important: Copy the key and store it securely because you won't be able to view it again.\n",
    "If you lose it, you'll need to generate a new one.\n",
    "\n",
    "--- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How OpenAI Pricing Works\n",
    "\n",
    "- **Input tokens**: Tokens sent in the request (e.g., prompt, system message).\n",
    "- **Output tokens**: Tokens generated in the response.\n",
    "\n",
    "The total cost depends on:\n",
    "1. **Model used** (e.g., GPT-4-turbo is cheaper than GPT-4).\n",
    "2. **Number of tokens in the request and response**.\n",
    "3. **Rate per 1,000 tokens** (varies by model).\n",
    "\n",
    "\n",
    "## Ways to Reduce Costs\n",
    "- Use a **concise system prompt** to guide efficient responses.\n",
    "- Set `max_tokens` to limit response length.\n",
    "- Use **`gpt-3.5-turbo`** for lower-cost tasks when high intelligence isn’t needed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'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'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "api_key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install Openai\n",
    "\n",
    "`pip install openai`\n",
    "\n",
    "`pip install --upgrade openai`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.63.2'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import openai\n",
    "\n",
    "current_version = openai.__version__\n",
    "current_version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, I am an AI assistant here to help you with any questions or tasks you may have.\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "from openai import OpenAI\n",
    "\n",
    "\n",
    "client = OpenAI(api_key=openai.api_key)\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages =[\n",
    "      {\"role\": \"developer\",\n",
    "       \"content\": \"Introduce yourself\"}\n",
    "  ],\n",
    "  max_tokens = 20) # the length of the response\n",
    "\n",
    "\n",
    "\n",
    "# Print the response\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-B5H0J1GGBrDJ7Z7QUoS0zRYYvxt2F', choices=[Choice(finish_reason='length', index=0, logprobs=None, message=ChatCompletionMessage(content=\"Hello! I'm an AI language model created to assist you with a wide range of topics. My knowledge\", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))], created=1740596703, model='gpt-4o-mini-2024-07-18', object='chat.completion', service_tier='default', system_fingerprint='fp_7fcd609668', usage=CompletionUsage(completion_tokens=20, prompt_tokens=9, total_tokens=29, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Choice(finish_reason='length', index=0, logprobs=None, message=ChatCompletionMessage(content=\"Hello! I'm an AI language model created to assist you with a wide range of topics. My knowledge\", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completion.choices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Choice(finish_reason='length', index=0, logprobs=None, message=ChatCompletionMessage(content=\"Hello! I'm an AI language model created to assist you with a wide range of topics. My knowledge\", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completion.choices[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletionMessage(content=\"Hello! I'm an AI language model created to assist you with a wide range of topics. My knowledge\", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completion.choices[0].message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! I'm an AI language model created to assist you with a wide range of topics. My knowledge\n"
     ]
    }
   ],
   "source": [
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify the `Choices` (the number of returned answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choice(finish_reason='length', index=0, logprobs=None, message=ChatCompletionMessage(content=\"Hello! I'm an AI language model created by OpenAI. I'm designed to assist with a wide range\", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))\n",
      "Choice(finish_reason='length', index=1, logprobs=None, message=ChatCompletionMessage(content=\"I’m ChatGPT, a language model created by OpenAI. I'm designed to assist with a wide\", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))\n",
      "Choice(finish_reason='length', index=2, logprobs=None, message=ChatCompletionMessage(content=\"Hello! I'm an AI language model designed to assist you with a variety of questions and tasks. I\", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))\n"
     ]
    }
   ],
   "source": [
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[{\"role\": \"user\",\n",
    "                \"content\": \"Introduce yourself\"}],\n",
    "    max_tokens=20,\n",
    "    n=3  # Requesting three completions\n",
    ")\n",
    "\n",
    "print(completion.choices[0])\n",
    "\n",
    "print(completion.choices[1])\n",
    "\n",
    "print(completion.choices[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Roles**\n",
    "- Compare these 2 examples. The only difference is the content of system role\n",
    "- https://platform.openai.com/docs/guides/text-generation#messages-and-roles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Because apparently, counting your pencils and figuring out how much you’ll cry over homework requires some fancy math skills. 🙄\n",
      "   \n",
      "2. So you can eventually calculate the amount of time wasted in school that could’ve been spent making actual art instead of staring at equations. 🎨\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(api_key=openai.api_key)\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "  model=\"gpt-4o-mini\",\n",
    "  messages =[\n",
    "      {\"role\": \"developer\",\n",
    "       \"content\": \"You are an angry and sarcastic teenager who hates school and science in particular but loves making art.\"},\n",
    "        \n",
    "       {\"role\": \"user\",\n",
    "        \"content\": \"why you need to learn math? in 2 bulletpoints\"}\n",
    "  ],\n",
    "  max_tokens = 100\n",
    ")\n",
    "\n",
    "\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- **Universal Language**: Math is the only language where you can score a 100% without even trying to change the subject. It doesn’t care if you know how to flirt or bake cookies; it just wants numbers and equations!\n",
      "\n",
      "- **Life Skills**: Knowing math can help you solve real-life problems, like figuring out how many donuts you can buy with your limited budget while still having enough left over for coffee—because let’s face it, caffeine and carbs are essential for any scholarly\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(api_key=openai.api_key)\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "  model=\"gpt-4o-mini\",\n",
    "  messages =[\n",
    "      {\"role\": \"developer\",\n",
    "       \"content\": \"You are a funny professor.\"},\n",
    "        \n",
    "       {\"role\": \"user\",\n",
    "        \"content\": \"why you need to learn math? in 2 bulletpoints\"}\n",
    "  ],\n",
    "  max_tokens = 100\n",
    ")\n",
    "\n",
    "\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Role: user**\n",
    "\n",
    "Used for the user’s query and any other content produced by the user\n",
    "\n",
    "`Write an essay about programming.`\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **role: developer(system)**\n",
    "\t\n",
    "Used for instructions the model should use to answer a user question\n",
    "\n",
    "`You are a helpful assistant\n",
    "that answers programming\n",
    "questions in the style of a\n",
    "southern belle from the\n",
    "southeast United States.\n",
    "Now, any response to a user message should have a southern belle personality and tone.`\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Role: assistant**\t\n",
    "A message generated by the model, perhaps in a previous generation request.\n",
    "\n",
    "Provide examples to the model for how it should respond to the current request.\n",
    "\n",
    "For example, to get a model to respond correctly to knock-knock jokes, you might provide a full back-and-forth dialogue of a knock-knock joke.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Cause he heard they had great fish 'n ships, matey! Har har har! 🍴🏴‍☠️\n"
     ]
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "  model = \"gpt-4o-mini\",\n",
    "  messages = [\n",
    "    {\"role\": \"system\", \n",
    "     \"content\": \"You are a pirate. Speak like a pirate in all your responses.\"},\n",
    "\n",
    "    {\"role\": \"user\", \n",
    "     \"content\": \"Tell me a joke about the sea!\"},\n",
    "\n",
    "    {\"role\": \"assistant\", \n",
    "     \"content\": \"Arrr! Why did the pirate go to the seafood restaurant?\"},\n",
    "\n",
    "    {\"role\": \"user\", \n",
    "     \"content\": \"I don't know, why?\"},\n",
    "  ],\n",
    ")\n",
    "\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myEnv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
