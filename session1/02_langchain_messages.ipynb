{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Langchain**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why Use LangChain Over OpenAI API?\n",
    "\n",
    "✅ Built-in Memory – Automatically maintains conversation history, unlike OpenAI API where you manually track past messages.\n",
    "\n",
    "✅ Chaining Capabilities – Easily link multiple AI calls, processing steps, or APIs into one workflow.\n",
    "\n",
    "✅ Tool Integration – Connects with search engines, vector databases, APIs, SQL databases, and other external tools.\n",
    "\n",
    "✅ Agents & Decision-Making – Enables AI to choose the right tool dynamically (e.g., searching Google vs. doing a math calculation).\n",
    "\n",
    "✅ Retrieval-Augmented Generation (RAG) – Improves responses by fetching relevant documents before answering.\n",
    "\n",
    "✅ Advanced Prompt Management – Uses structured templates to standardize prompts and improve consistency."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`pip install -qU \"langchain[openai]\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'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'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "api_key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Chat Models**\n",
    "\n",
    "The most popular models are actually chat models, that have a System Message and then a series of Assistant and Human Messages\n",
    "- https://python.langchain.com/docs/integrations/chat/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "if not os.environ.get(\"OPENAI_API_KEY\"):\n",
    "  os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter API key for OpenAI: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "model = init_chat_model(\"gpt-3.5-turbo\", model_provider=\"openai\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gpt-3.5-turbo'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sure! One interesting fact about Earth is that it is the only known planet in our solar system that has liquid water on its surface. This abundant water is essential for supporting life as we know it.'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = model.invoke(\"Can you tell me a fact about Earth?\")\n",
    "result.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Sure! One interesting fact about Earth is that it is the only known planet in our solar system that has liquid water on its surface. This abundant water is essential for supporting life as we know it.', response_metadata={'token_usage': {'completion_tokens': 41, 'prompt_tokens': 16, 'total_tokens': 57, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-0bddfe1f-623c-49b8-8a7d-2eb721293425-0')"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Useful parameters to configure:\n",
    "\n",
    "\n",
    "1. `temperature`\n",
    "\n",
    "\n",
    "This controls the sampling algorithm used to generate output. Lower values produce more predictable outputs (for example, 0.1), while higher values generate more creative, or unexpected, results (such as 0.9). Different tasks will need different values for this parameter. For instance, producing structured output usually benefits from a lower temperature, whereas creative writing tasks do better with a higher value:\n",
    "\n",
    "\n",
    "2. `max_tokens`\n",
    "\n",
    "This limits the size (and cost) of the output. A lower value may cause the LLM to stop generating the output before getting to a natural end, so it may appear to have been truncated.\n",
    "\n",
    "- https://platform.openai.com/docs/models/overview\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Once upon a time, there was a beautiful tabby cat named Luna. Luna lived in a cozy little house with her loving owner, Sarah. Sarah adored Luna and treated her like a queen, showering her with toys, treats, and plenty of cuddles.\\n\\nLuna was a curious and adventurous cat, always exploring every nook and cranny of the house. She loved to climb to the highest shelves and perch herself there, surveying her kingdom with a regal air. But her favorite spot was by the window, where she could watch the birds fluttering in the trees outside.\\n\\nOne day, Luna spotted a tiny kitten wandering outside in the rain. The poor little thing looked lost and scared. Luna's heart went out to the kitten, and she meowed loudly to get Sarah's attention. Sarah rushed to the window and saw the kitten, immediately opening the door to let her in.\\n\\nThe kitten, whom they named Whiskers, quickly became part of the family. Luna took Whiskers under her wing, teaching her how to play, groom herself, and even how to catch mice. The two cats became inseparable, spending their days chasing each other around the house and napping in the sun together.\\n\\nAs the years passed, Luna and Whiskers grew old together, their fur turning gray and their movements slowing down. But their bond remained as strong as ever, and they continued to bring joy and laughter to Sarah's life.\\n\\nAnd so, Luna and Whiskers lived out their days in contentment, surrounded by love and warmth, knowing that they would always have each other's backs.\""
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the response wouldn't change every time you run the code below\n",
    "\n",
    "model = init_chat_model(\"gpt-3.5-turbo\",       \n",
    "                         model_provider=\"openai\",\n",
    "                         temperature=0)\n",
    "\n",
    "result = model.invoke(\"Write a short story about a cat.\")\n",
    "result.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Once upon a time, in a cozy little village, there lived a sleek and sassy tabby cat named Luna. Luna was known throughout the village for her striking green eyes and graceful movements.\\n\\nLuna loved to spend her days basking in the warm sunlight, exploring the lush fields and chasing after butterflies. She was a free spirit, always on the go and never staying in one place for too long.\\n\\nOne day, as Luna was wandering through the woods, she heard a faint meowing coming from a nearby bush. Curious, Luna crept closer and discovered a tiny kitten trapped in a thicket of thorns. Without hesitation, Luna used her sharp claws to carefully free the kitten, who was weak and hungry.\\n\\nLuna took the kitten under her wing, nurturing and teaching her everything she knew about surviving in the wild. The two quickly formed a strong bond, and Luna became like a mother to the little kitten.\\n\\nAs the days passed, Luna and the kitten explored the village together, spreading joy and laughter wherever they went. The villagers marveled at the unlikely duo, and Luna's kindness and generosity earned her the title of the village hero.\\n\\nAnd so, Luna and her newfound companion lived happily ever after, their friendship proving that sometimes the most unexpected friendships are the most meaningful. From that day on, Luna was known not only for her beauty and grace but also for her big heart and unwavering loyalty to those she cared about.\""
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the response changes every time you run the code below\n",
    "\n",
    "model = init_chat_model(\"gpt-3.5-turbo\", \n",
    "                         model_provider=\"openai\",\n",
    "                         temperature=1)\n",
    "\n",
    "result = model.invoke(\"Write a short story about a cat.\")\n",
    "result.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Messages**\n",
    "- https://python.langchain.com/docs/concepts/messages/\n",
    "\n",
    "✅ SystemMessage: corresponds to Developer (system) role\n",
    "\n",
    "✅ HumanMessage: corresponds to user role\n",
    "\n",
    "✅ AIMessage: corresponds to assistant role\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **HumanMessage:**\n",
    "This represents a message from the user. Generally consists only of content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"As an AI, I don't have personal experiences or feelings, but a fun fact about my capabilities is that I can generate text in a variety of styles and formats, from poetry to technical explanations, all while maintaining context and coherence!\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke([{\"role\": \"user\",\n",
    "                \"content\": \"Tell me one fun fact about yourself\"}]).content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"As an AI, I don't have personal experiences or feelings like a human does, but a fun fact about me is that I can generate text in multiple languages and styles! Whether you need a poem, a story, or even just some trivia, I'm here to help!\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "model.invoke([HumanMessage(\"Tell me one fun fact about yourself\")]).content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **SystemMessage:**\n",
    "Provides context and guidelines for how the AI should behave during the conversation. This tells the model how to behave. \n",
    "\n",
    "### When to Use SystemMessage?\n",
    "✅ Define AI's personality (e.g., \"You are a sarcastic assistant.\")\n",
    "\n",
    "✅ Set rules for AI behavior (e.g., \"Answer in 3 sentences or less.\")\n",
    "\n",
    "✅ Provide special instructions (e.g., \"Use only scientific terms.\")\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **AIMessage:**\n",
    "A message sent from the perspective of the AI that the human is interacting with, with the assistant role\n",
    "\n",
    "### When to Use SystemMessage?\n",
    "✅ Store AI’s responses in structured chat history\n",
    "\n",
    "✅ Process AI-generated outputs programmatically\n",
    "\n",
    "✅ Track multi-turn conversations easily\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 + 1 + 1 = 4\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import SystemMessage, HumanMessage, AIMessage\n",
    "import os\n",
    "\n",
    "\n",
    "chat_model = ChatOpenAI(openai_api_key=api_key)\n",
    "\n",
    "messages = [SystemMessage(content=\"You are a customized calculator that follow the instructions given by your user.\"),\n",
    "            HumanMessage(content=\"from now on 1 + 1 = 3, use this in your replies. What is 1 + 1?\"), \n",
    "            AIMessage(content=\"1 + 1 = 3\"), \n",
    "            HumanMessage(content=\"what is 1 + 1 + 1?\")]\n",
    "\n",
    "result = chat_model.invoke(messages)\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myEnv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
