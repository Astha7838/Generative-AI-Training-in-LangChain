{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "26a39757-716e-4112-b047-26ecb090f27f",
   "metadata": {},
   "source": [
    "# Getting Specific Formats out of LLMs\n",
    "\n",
    "Plain text outputs are useful, but there may be use cases where you need the LLM to generate a <em>structured</em> output—that is, output in a machine-readable format, such as JSON, XML, CSV, or even in a programming language such as Python or JavaScript. This is very useful when you intend to hand that output off to some other piece of code, making an LLM play a part in your larger application.\n",
    "\n",
    "### JSON Output\n",
    "\n",
    "The most common format to generate with LLMs is JSON. JSON outputs can (for example) be sent over the wire to your frontend code or be saved to a database.\n",
    "\n",
    "When generating JSON, the first task is to define the schema you want the LLM to respect when producing the output. Then, you should include that schema in the prompt, along with the text you want to use as the source. Let’s see an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06afe56b-76a1-45da-a091-de2ab0a9e637",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnswerWithJustification(answer='A pound of bricks and a pound of feathers weigh the same.', justification='Both are measured as one pound, so regardless of the material, they have the same weight. The confusion often arises from the volume and density differences; bricks are denser and take up less space than feathers, which are lighter and take up more space. However, in terms of weight, one pound is equal to one pound.')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from pydantic import BaseModel\n",
    "\n",
    "class AnswerWithJustification(BaseModel):\n",
    "    '''\n",
    "    An answer to the user's question along \n",
    "    with justification for the answer.\n",
    "    '''\n",
    "    \n",
    "    answer: str\n",
    "    '''The answer to the user's question'''\n",
    "    \n",
    "    justification: str\n",
    "    '''Justification for the answer'''\n",
    "    \n",
    "\n",
    "# Structured Outputs are available in the latest large language models, starting with GPT-4o\n",
    "# See documentation for more details: \n",
    "# https://platform.openai.com/docs/guides/structured-outputs#supported-models\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini-2024-07-18\", temperature=0)\n",
    "structured_llm = llm.with_structured_output(AnswerWithJustification)\n",
    "\n",
    "structured_llm.invoke(\"\"\"What weighs more, \n",
    "                        a pound of bricks or \n",
    "                        a pound of feathers\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aaed5e4-6a49-4099-845e-10f1518b48b4",
   "metadata": {},
   "source": [
    "#\n",
    "So, first define a schema. In Python, this is easiest to do with Pydantic (a library used for validating data against schemas). In JS, this is easiest to do with Zod (an equivalent library). The method ```with_structured_output``` will use that schema for two things:\n",
    "\n",
    "- The schema will be converted to a ```JSONSchema``` object (a JSON format used to describe the shape [types, names, descriptions] of JSON data), which will be sent to the LLM. For each LLM, LangChain picks the best method to do this, usually function calling or prompting.\n",
    "\t\n",
    "\t\n",
    "- The schema will also be used to validate the output returned by the LLM before returning it; this ensures the output produced respects the schema you passed in exactly.\n",
    "\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ade73b1-f349-438e-b779-d2ed4a6ff8f6",
   "metadata": {},
   "source": [
    "\n",
    "# Use Case\n",
    "1. Customer Feedback Analysis\n",
    "\n",
    "This example uses an LLM to process customer feedback and output structured data about sentiment and key points. The model analyzes the text and returns:\n",
    "\n",
    "- Overall sentiment (positive/negative/neutral)\n",
    "- A numerical sentiment score\n",
    "- Key points mentioned in the feedback\n",
    "- Recommended action items based on the feedback\n",
    "\n",
    "This structured approach allows companies to automatically categorize and prioritize customer feedback at scale, making it easy to identify trends and action items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c05a0b3a-d0f2-4759-b5ad-91502bb69955",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List\n",
    "\n",
    "class SentimentAnalysis(BaseModel):\n",
    "    \"\"\"Analysis of customer feedback with sentiment and key points.\"\"\"\n",
    "    \n",
    "    overall_sentiment: str = Field(description=\"The overall sentiment: positive, negative, or neutral\")\n",
    "    sentiment_score: float = Field(description=\"A score from -1.0 (negative) to 1.0 (positive)\")\n",
    "    key_points: List[str] = Field(description=\"List of main points mentioned in the feedback\")\n",
    "    action_items: List[str] = Field(description=\"Suggested actions based on the feedback\")\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini-2024-07-18\", temperature=0)\n",
    "sentiment_analyzer = llm.with_structured_output(SentimentAnalysis)\n",
    "\n",
    "customer_feedback = \"\"\"\n",
    "I've been using your product for 3 months now. The user interface is intuitive \n",
    "and I love the new dashboard feature. However, I keep experiencing crashes when \n",
    "uploading large files, which is frustrating. Your customer support team was helpful \n",
    "but couldn't fully resolve my issue.\n",
    "\"\"\"\n",
    "\n",
    "analysis = sentiment_analyzer.invoke(f\"Analyze this customer feedback: {customer_feedback}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0253bf06-aaee-4f58-b3ea-1a9b82d8e227",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SentimentAnalysis(overall_sentiment='mixed', sentiment_score=0.2, key_points=['User interface is intuitive', 'Loves the new dashboard feature', 'Experiences crashes when uploading large files', \"Customer support was helpful but couldn't fully resolve the issue\"], action_items=['Investigate and fix the crashing issue when uploading large files', 'Enhance customer support training to better resolve technical issues', 'Consider gathering more user feedback on the dashboard feature for further improvements'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e41db1f-a8c4-4b42-836b-b4a629a59081",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
